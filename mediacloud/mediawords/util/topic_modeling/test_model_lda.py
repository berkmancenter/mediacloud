import unittest
import logging

# from mediawords.db import connect_to_db
from mediawords.util.topic_modeling.sample_handler import SampleHandler
from mediawords.util.topic_modeling.token_pool import TokenPool
from mediawords.util.topic_modeling.model_lda import ModelLDA
from typing import Dict, List


class TestModelLDA(unittest.TestCase):
    """
    Test the methods in model_lda.py
    """
    @classmethod
    def setUpClass(cls):
        """
        Setting up the whole class (i.e. only need to run once)
        """
        cls.setup_test_data()

    @classmethod
    def setup_test_data(cls):
        """
        Prepare the token pool and other data
        """
        # token_pool = TokenPool(connect_to_db())
        token_pool = TokenPool(SampleHandler())

        cls._story_tokens = token_pool.output_tokens()
        cls._flat_story_tokens = cls._flatten_story_tokens(self=cls())
        cls._lda_model = ModelLDA()
        cls._lda_model.add_stories(cls._story_tokens)
        cls._optimal_topic_num_poly = cls._lda_model.tune_with_polynomial()

        cls._topics_via_poly \
            = cls._lda_model.summarize_topic(total_topic_num=cls._optimal_topic_num_poly)

        logging.getLogger("lda").setLevel(logging.WARNING)
        logging.getLogger("gensim").setLevel(logging.WARNING)

    def _flatten_story_tokens(self) -> Dict[int, List[str]]:
        """
        Flatten all tokens of a story into a single dimension list
        :return: A dictionary of {story_id : [all tokens of that story]}
        """
        flat_story_tokens = {}
        for story in self._story_tokens.items():
            story_id = story[0]
            grouped_tokens = story[1]
            flat_story_tokens[story_id] \
                = [tokens for sentence_tokens in grouped_tokens for tokens in sentence_tokens]
        return flat_story_tokens

    def test_one_to_one_relationship(self):
        """
        Pass topics generated by both methods to _check_one_to_one_relationship()
        """
        self._check_one_to_one_relationship(topics=self._topics_via_poly)

    def _check_one_to_one_relationship(self, topics: Dict[int, List]):
        """
        Test if there is one-to-one relationship for articles and topics
        (i.e. no mysteries topic id or missing article id)
        """
        topic_ids = topics.keys()
        story_ids = self._story_tokens.keys()

        for topic_id in topic_ids:
            unittest.TestCase.assertTrue(
                self=self,
                expr=(topic_id in story_ids),
                msg="Mysteries topic id: {}".format(topic_id))

        for article_id in story_ids:
            unittest.TestCase.assertTrue(
                self=self,
                expr=(article_id in topic_ids),
                msg="Missing article id: {}".format(article_id))

    def _check_story_contains_topic_word(self, topics: Dict[int, List]):
        """
        Test if each story contains at least one of the topic words
        """
        story_ids = self._story_tokens.keys()

        for story_id in story_ids:
            # Due to the nature of this algorithm, if a story is too short, the words in it might
            # not repeat enough times to be considered as a valid topic. Hence
            if len(self._flat_story_tokens.get(story_id)) < 25:
                return
            exist = False
            for topic in iter(topics.get(story_id)):
                exist = topic in self._flat_story_tokens.get(story_id) or exist
                if exist:
                    break
            if not exist:
                raise ValueError("Story {id} does not contain any of its topic words: {topic}\n"
                                 "Story tokens:\n {tokens}"
                                 .format(id=story_id, topic=topics.get(story_id),
                                         tokens=self._flat_story_tokens.get(story_id)))

    def test_default_topic_params(self):
        """
        Pass topics generated by both methods to _check_default_topic_params()
        """
        self._check_default_topic_params(topics=self._topics_via_poly)

    def _check_default_topic_params(self, topics: Dict[int, List[str]]):
        """
        Test if the correct number of words for each topic is returned
        """
        default_word_num = 4
        for topics in topics.values():
            unittest.TestCase.assertEqual(
                self=self, first=default_word_num, second=len(topics),
                msg="Default word number ({}) != word number ({})\nTopic = {}"
                    .format(default_word_num, len(topics), topics))

    def test_highest_likelihood(self):
        """
        Pass topic_num and the name of tuning method to _check_highest_likelihood
        Designed in this way to allow extensibility
        (i.e. append more topic_num-name_of_tuning pair)
        """
        self._check_highest_likelihood(num=self._optimal_topic_num_poly, name="Polynomial")

    def _check_highest_likelihood(self, num: int, name: str):
        """
        Test if the result is the most accurate one
        :param num: optimal topic_num found by polynomial
        :param name: the name of training method used
        """
        optimal_likelihood = self._lda_model.evaluate(topic_num=num)[1]
        other_nums = [0, 1, num-1, num+1, num*2]

        for other_num in other_nums:
            if (other_num == num) or num < 0:
                continue
            other_likelihood = self._lda_model.evaluate(topic_num=other_num)[1]
            unittest.TestCase.assertGreaterEqual(
                self=self,
                a=optimal_likelihood,
                b=other_likelihood,
                msg="Topic num {} has a better likelihood {} than {}  with {}:{}"
                    .format(other_num, other_likelihood, name, num, optimal_likelihood))

if __name__ == '__main__':
    unittest.main()
